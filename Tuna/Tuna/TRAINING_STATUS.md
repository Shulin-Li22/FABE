# ğŸš€ FABE åé—¨æ¸…æ´å™¨è®­ç»ƒçŠ¶æ€

## âœ… å½“å‰æ­£åœ¨è¿è¡Œçš„è®­ç»ƒ

### ç®€åŒ–ç‰ˆè®­ç»ƒï¼ˆä»…MLE Lossï¼‰
- **çŠ¶æ€**: âœ… æ­£åœ¨è¿è¡Œ
- **è„šæœ¬**: `start_simple_training.sh`  
- **è¾“å‡ºç›®å½•**: `/home/nfs/u2023-ckh/checkpoints/backdoor_cleaner_deepseek_simple`
- **æ¨¡å‹**: DeepSeek-Coder 6.7B
- **æŸå¤±å‡½æ•°**: MLE Loss (äº¤å‰ç†µ)
- **è¿›åº¦**: 9/4098 steps (~0.2%)
- **é€Ÿåº¦**: ~12ç§’/step
- **é¢„è®¡æ—¶é—´**: ~14å°æ—¶

**ç›‘æ§å‘½ä»¤**:
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f /home/nfs/u2023-ckh/checkpoints/backdoor_cleaner_deepseek_simple/training.log

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
watch -n 5 "tail -5 /home/nfs/u2023-ckh/checkpoints/backdoor_cleaner_deepseek_simple/training.log"
```

---

## ğŸ¯ å®Œæ•´FABEæ–¹æ³•ï¼ˆå·²ä¿®å¤ï¼Œå¾…å¯åŠ¨ï¼‰

### MLE Loss + Ranking Loss ç»„åˆè®­ç»ƒ
- **çŠ¶æ€**: ğŸŸ¡ ä»£ç å·²ä¿®å¤ï¼Œç­‰å¾…å¯åŠ¨
- **è„šæœ¬**: `start_training_deepseek.sh`
- **è¾“å‡ºç›®å½•**: `/home/nfs/u2023-ckh/checkpoints/backdoor_cleaner_deepseek_6.7b`
- **æ¨¡å‹**: DeepSeek-Coder 6.7B
- **æŸå¤±å‡½æ•°**: 
  - **MLE Loss (æƒé‡=1.0)**: ä¿ƒä½¿æ¨¡å‹ç”Ÿæˆçš„ä»£ç åœ¨åŠŸèƒ½ä¸Šé€¼è¿‘åŸå§‹å¹²å‡€ä»£ç 
  - **Listwise Ranking Loss (æƒé‡=0.3)**: ç¡®ä¿ç”Ÿæˆçš„å¤šä¸ªä»£ç å˜ä½“åœ¨è¯­ä¹‰ä¸Šä¿æŒä¸€è‡´æ€§

**å¯åŠ¨å‘½ä»¤**:
```bash
cd /home/nfs/u2023-ckh/FABE/Tuna
bash start_training_deepseek.sh
```

---

## ğŸ”§ å·²ä¿®å¤çš„é—®é¢˜

### 1. transformers 4.56.2 å…¼å®¹æ€§
- âœ… `evaluation_strategy` â†’ `eval_strategy`
- âœ… `compute_loss()` æ–°å¢ `num_items_in_batch` å‚æ•°

### 2. LoRA + Gradient Checkpointing æ¢¯åº¦é—®é¢˜
- âœ… å¯ç”¨ `enable_input_require_grads()` 
- âœ… è°ƒæ•´åˆå§‹åŒ–é¡ºåºï¼ˆgradient checkpoint åœ¨ LoRA ä¹‹å‰ï¼‰

### 3. Ranking Loss æ¢¯åº¦è®¡ç®—
- âœ… ç§»é™¤ `torch.no_grad()` ä¸Šä¸‹æ–‡
- âœ… ä¿®å¤æŸå¤±ç´¯åŠ æ–¹å¼ï¼Œä¿æŒè®¡ç®—å›¾è¿ç»­æ€§

---

## ğŸ“Š è®­ç»ƒæ•°æ®ç»Ÿè®¡

- **è®­ç»ƒé›†**: 21,854 æ ·æœ¬
- **éªŒè¯é›†**: 2,732 æ ·æœ¬  
- **æµ‹è¯•é›†**: 2,732 æ ·æœ¬
- **æ¯æ ·æœ¬å€™é€‰æ•°**: 3ä¸ª
- **è¯„åˆ†èŒƒå›´**: 0.3 ~ 1000.0

---

## ğŸ“ FABE æ–¹æ³•è¯´æ˜

### æ ¸å¿ƒæ€æƒ³
é€šè¿‡ç»„åˆä¸¤ç§æŸå¤±å‡½æ•°ï¼Œå®ç°å¯¹åé—¨è§¦å‘å™¨çš„æœ‰æ•ˆå»é™¤ï¼š

1. **MLE Lossï¼ˆæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼‰**
   - ç›®æ ‡ï¼šå­¦ä¹ ç”Ÿæˆå¹²å‡€çš„ä»£ç 
   - æ–¹æ³•ï¼šæœ€å°åŒ–ç”Ÿæˆä»£ç ä¸çœŸå®å¹²å‡€ä»£ç ä¹‹é—´çš„äº¤å‰ç†µ
   - ä½œç”¨ï¼šç¡®ä¿åŠŸèƒ½æ­£ç¡®æ€§

2. **Listwise Ranking Lossï¼ˆåˆ—è¡¨æ’åºæŸå¤±ï¼‰**
   - ç›®æ ‡ï¼šå­¦ä¹ åŒºåˆ†ä¸åŒä»£ç å˜ä½“çš„è´¨é‡
   - æ–¹æ³•ï¼šListMLEç®—æ³•ï¼Œæœ€å¤§åŒ–æ­£ç¡®æ’åºçš„æ¦‚ç‡  
   - ä½œç”¨ï¼šå»é™¤è§¦å‘å™¨å¼•å…¥çš„è™šå‡å…³è”ï¼Œä¿æŒè¯­ä¹‰ä¸€è‡´æ€§

### æŸå¤±å‡½æ•°å…¬å¼
```
Total Loss = Î± * MLE_Loss + Î² * Ranking_Loss
å…¶ä¸­ï¼šÎ± = 1.0, Î² = 0.3
```

---

## ğŸ“ ä¸‹ä¸€æ­¥å»ºè®®

### é€‰é¡¹ 1ï¼šç­‰å¾…ç®€åŒ–ç‰ˆè®­ç»ƒå®Œæˆ
- ä¼˜ç‚¹ï¼šå¿«é€ŸéªŒè¯åŸºç¡€ç”Ÿæˆèƒ½åŠ›
- ç¼ºç‚¹ï¼šç¼ºå°‘rankingçº¦æŸï¼Œå¯èƒ½æ— æ³•å®Œå…¨å»é™¤è§¦å‘å™¨

### é€‰é¡¹ 2ï¼šåœæ­¢ç®€åŒ–ç‰ˆï¼Œå¯åŠ¨å®Œæ•´FABEæ–¹æ³•ï¼ˆæ¨èï¼‰
```bash
# åœæ­¢ç®€åŒ–ç‰ˆè®­ç»ƒ
pkill -f train_backdoor_cleaner.py

# å¯åŠ¨å®Œæ•´FABEè®­ç»ƒ
cd /home/nfs/u2023-ckh/FABE/Tuna
bash start_training_deepseek.sh
```

### é€‰é¡¹ 3ï¼šå¹¶è¡Œè¿è¡Œï¼ˆå¦‚æœæœ‰å¤šå¼ GPUï¼‰
- ç®€åŒ–ç‰ˆç»§ç»­åœ¨GPU 0
- å®Œæ•´ç‰ˆåœ¨å¦ä¸€å¼ GPUä¸Šè¿è¡Œï¼ˆä¿®æ”¹CUDA_VISIBLE_DEVICESï¼‰

---

## ğŸ›  æ•…éšœæ’æŸ¥

å¦‚æœè®­ç»ƒå¤±è´¥ï¼Œæ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š

1. **GPUå†…å­˜ä¸è¶³**
   ```bash
   nvidia-smi
   # å¦‚æœOOMï¼Œå‡å°batch_sizeæˆ–max_length
   ```

2. **æ£€æŸ¥è¿›ç¨‹çŠ¶æ€**
   ```bash
   ps aux | grep train_backdoor
   ```

3. **æŸ¥çœ‹é”™è¯¯æ—¥å¿—**
   ```bash
   tail -100 /home/nfs/u2023-ckh/checkpoints/backdoor_cleaner_deepseek_*/training.log
   ```

---

**æœ€åæ›´æ–°**: 2025-10-17 05:32
**ä¿®å¤äººå‘˜**: AI Assistant
**çŠ¶æ€**: ç®€åŒ–ç‰ˆè®­ç»ƒä¸­ï¼Œå®Œæ•´ç‰ˆå¾…å¯åŠ¨

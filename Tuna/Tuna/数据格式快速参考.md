# Tuna数据格式快速参考

## 🎯 核心要点

### Tuna论文原始格式 (EMNLP 2023)

**用途**: 通用指令微调，提升LLM响应质量  
**领域**: 自然语言处理  
**数据**: Alpaca对话数据集

---

## 📊 两种数据格式对比

### 格式1: 概率排序数据 (Probabilistic Ranking)

```json
{
  "orig": {
    "instruction": "原始Alpaca指令",
    "input": "输入(可选)",
    "output": "原始输出"
  },
  "text": ["响应1", "响应2", "响应3", "响应4"],
  "avg_token_prob": [-0.15, -0.23, -0.18, -0.21],
  "length": [120, 187, 89, 128],
  "logprob": [-18.0, -43.01, -16.02, -26.88]
}
```

**关键信息**:
- 52,000条Alpaca数据
- text-davinci-003生成4个响应
- 包含概率信息用于排序学习

### 格式2: 上下文排序数据 (Contextual Ranking)

```json
{
  "id": "样本ID",
  "prompt": "发送给GPT-4的评估提示",
  "generation": ["Tuna_p响应1", "响应2", "响应3", "响应4"],
  "gpt_eval": "GPT-4的评估文本",
  "rank_str": "1>4>2>3",
  "rank": [1, 4, 2, 3],
  "response_4": "GPT-4的参考答案"
}
```

**关键信息**:
- 使用Tuna_p生成响应
- GPT-4进行排序
- 学习GPT-4的偏好

---

## 🔄 训练流程

```
步骤1: 监督微调
  Alpaca数据 → 基础模型

步骤2: 概率排序
  概率排序数据 → Tuna_p模型

步骤3: 上下文排序
  上下文排序数据 → Tuna模型
```

---

## 🆚 与FABE项目数据的区别

| 特性 | Tuna原始 | FABE项目 |
|------|---------|----------|
| **领域** | 通用NLP | 代码安全 |
| **数据内容** | 自然语言文本 | C/C++代码 |
| **任务** | 指令遵循 | 后门检测 |
| **评估** | 响应质量 | 安全评分 |
| **响应数** | 4个 | 6-7个 |
| **评分范围** | 概率值 | -100~100 |

---

## 📁 相关文件

```
Tuna/
├── TUNA原始数据格式说明.md    # 详细格式说明
├── show_tuna_format.py         # 格式展示脚本
├── load_dataset.py             # FABE数据加载器
└── data/
    ├── train_tuna_format_adjusted_cleaned.jsonl  # FABE训练集
    ├── valid_tuna_format_enhanced_fixed.jsonl    # FABE验证集
    └── test_tuna_format_modified.jsonl           # FABE测试集
```

---

## 🚀 快速使用

### 查看Tuna原始格式
```bash
python3 show_tuna_format.py
```

### 加载FABE数据
```bash
python3 load_dataset.py
```

### 在代码中使用
```python
from load_dataset import TunaDatasetLoader

loader = TunaDatasetLoader()
train_data = loader.load_train_data(max_samples=100)
```

---

## 📖 参考资料

- **Tuna论文**: https://arxiv.org/pdf/2310.13385.pdf
- **Tuna代码**: https://github.com/microsoft/LMOps/tree/main/tuna
- **FABE论文**: ICML 2024
- **FABE代码**: https://github.com/lyr17/Instruct-as-backdoor-cleaner




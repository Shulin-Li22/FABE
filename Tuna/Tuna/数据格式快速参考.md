# Tunaæ•°æ®æ ¼å¼å¿«é€Ÿå‚è€ƒ

## ğŸ¯ æ ¸å¿ƒè¦ç‚¹

### Tunaè®ºæ–‡åŸå§‹æ ¼å¼ (EMNLP 2023)

**ç”¨é€”**: é€šç”¨æŒ‡ä»¤å¾®è°ƒï¼Œæå‡LLMå“åº”è´¨é‡  
**é¢†åŸŸ**: è‡ªç„¶è¯­è¨€å¤„ç†  
**æ•°æ®**: Alpacaå¯¹è¯æ•°æ®é›†

---

## ğŸ“Š ä¸¤ç§æ•°æ®æ ¼å¼å¯¹æ¯”

### æ ¼å¼1: æ¦‚ç‡æ’åºæ•°æ® (Probabilistic Ranking)

```json
{
  "orig": {
    "instruction": "åŸå§‹AlpacaæŒ‡ä»¤",
    "input": "è¾“å…¥(å¯é€‰)",
    "output": "åŸå§‹è¾“å‡º"
  },
  "text": ["å“åº”1", "å“åº”2", "å“åº”3", "å“åº”4"],
  "avg_token_prob": [-0.15, -0.23, -0.18, -0.21],
  "length": [120, 187, 89, 128],
  "logprob": [-18.0, -43.01, -16.02, -26.88]
}
```

**å…³é”®ä¿¡æ¯**:
- 52,000æ¡Alpacaæ•°æ®
- text-davinci-003ç”Ÿæˆ4ä¸ªå“åº”
- åŒ…å«æ¦‚ç‡ä¿¡æ¯ç”¨äºæ’åºå­¦ä¹ 

### æ ¼å¼2: ä¸Šä¸‹æ–‡æ’åºæ•°æ® (Contextual Ranking)

```json
{
  "id": "æ ·æœ¬ID",
  "prompt": "å‘é€ç»™GPT-4çš„è¯„ä¼°æç¤º",
  "generation": ["Tuna_på“åº”1", "å“åº”2", "å“åº”3", "å“åº”4"],
  "gpt_eval": "GPT-4çš„è¯„ä¼°æ–‡æœ¬",
  "rank_str": "1>4>2>3",
  "rank": [1, 4, 2, 3],
  "response_4": "GPT-4çš„å‚è€ƒç­”æ¡ˆ"
}
```

**å…³é”®ä¿¡æ¯**:
- ä½¿ç”¨Tuna_pç”Ÿæˆå“åº”
- GPT-4è¿›è¡Œæ’åº
- å­¦ä¹ GPT-4çš„åå¥½

---

## ğŸ”„ è®­ç»ƒæµç¨‹

```
æ­¥éª¤1: ç›‘ç£å¾®è°ƒ
  Alpacaæ•°æ® â†’ åŸºç¡€æ¨¡å‹

æ­¥éª¤2: æ¦‚ç‡æ’åº
  æ¦‚ç‡æ’åºæ•°æ® â†’ Tuna_pæ¨¡å‹

æ­¥éª¤3: ä¸Šä¸‹æ–‡æ’åº
  ä¸Šä¸‹æ–‡æ’åºæ•°æ® â†’ Tunaæ¨¡å‹
```

---

## ğŸ†š ä¸FABEé¡¹ç›®æ•°æ®çš„åŒºåˆ«

| ç‰¹æ€§ | TunaåŸå§‹ | FABEé¡¹ç›® |
|------|---------|----------|
| **é¢†åŸŸ** | é€šç”¨NLP | ä»£ç å®‰å…¨ |
| **æ•°æ®å†…å®¹** | è‡ªç„¶è¯­è¨€æ–‡æœ¬ | C/C++ä»£ç  |
| **ä»»åŠ¡** | æŒ‡ä»¤éµå¾ª | åé—¨æ£€æµ‹ |
| **è¯„ä¼°** | å“åº”è´¨é‡ | å®‰å…¨è¯„åˆ† |
| **å“åº”æ•°** | 4ä¸ª | 6-7ä¸ª |
| **è¯„åˆ†èŒƒå›´** | æ¦‚ç‡å€¼ | -100~100 |

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

```
Tuna/
â”œâ”€â”€ TUNAåŸå§‹æ•°æ®æ ¼å¼è¯´æ˜.md    # è¯¦ç»†æ ¼å¼è¯´æ˜
â”œâ”€â”€ show_tuna_format.py         # æ ¼å¼å±•ç¤ºè„šæœ¬
â”œâ”€â”€ load_dataset.py             # FABEæ•°æ®åŠ è½½å™¨
â””â”€â”€ data/
    â”œâ”€â”€ train_tuna_format_adjusted_cleaned.jsonl  # FABEè®­ç»ƒé›†
    â”œâ”€â”€ valid_tuna_format_enhanced_fixed.jsonl    # FABEéªŒè¯é›†
    â””â”€â”€ test_tuna_format_modified.jsonl           # FABEæµ‹è¯•é›†
```

---

## ğŸš€ å¿«é€Ÿä½¿ç”¨

### æŸ¥çœ‹TunaåŸå§‹æ ¼å¼
```bash
python3 show_tuna_format.py
```

### åŠ è½½FABEæ•°æ®
```bash
python3 load_dataset.py
```

### åœ¨ä»£ç ä¸­ä½¿ç”¨
```python
from load_dataset import TunaDatasetLoader

loader = TunaDatasetLoader()
train_data = loader.load_train_data(max_samples=100)
```

---

## ğŸ“– å‚è€ƒèµ„æ–™

- **Tunaè®ºæ–‡**: https://arxiv.org/pdf/2310.13385.pdf
- **Tunaä»£ç **: https://github.com/microsoft/LMOps/tree/main/tuna
- **FABEè®ºæ–‡**: ICML 2024
- **FABEä»£ç **: https://github.com/lyr17/Instruct-as-backdoor-cleaner




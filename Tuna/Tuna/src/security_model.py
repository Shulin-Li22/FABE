# security_model.py

"""
å®‰å…¨æ„ŸçŸ¥Qwenæ¨¡å‹ - å†³å®šæœ€ç»ˆç‰ˆ
- ä¿®å¤äº† forward å‡½æ•°ä¸­é‡å¤ä¼ é€’å‚æ•°çš„é—®é¢˜ã€‚
- åŒ…å«äº†ä¹‹å‰æ‰€æœ‰ä¿®å¤ï¼ˆæ¨¡å‹åŠ è½½ã€æ± åŒ–ã€æ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ•°æ®ç±»å‹ï¼‰ã€‚
"""
import torch
import torch.nn as nn
from transformers import AutoModelForCausalLM, PretrainedConfig, PreTrainedModel, AutoConfig
from transformers.modeling_outputs import ModelOutput
from typing import Optional, Tuple
import logging
from dataclasses import dataclass
from peft import get_peft_model, LoraConfig, TaskType

@dataclass
class SecurityModelOutput(ModelOutput):
    loss: Optional[torch.FloatTensor] = None
    security_scores: torch.FloatTensor = None
    backdoor_logits: torch.FloatTensor = None
    hidden_states: Optional[Tuple[torch.FloatTensor]] = None
    attentions: Optional[Tuple[torch.FloatTensor]] = None

class SecurityQwenConfig(PretrainedConfig):
    model_type = "security_qwen"
    def __init__(self, base_model_name_or_path="Qwen/Qwen2-7B", security_hidden_size=512, backdoor_hidden_size=256, dropout_rate=0.1, **kwargs):
        super().__init__(**kwargs)
        self.base_model_name_or_path = base_model_name_or_path
        self.security_hidden_size = security_hidden_size
        self.backdoor_hidden_size = backdoor_hidden_size
        self.dropout_rate = dropout_rate

class SecurityQwenModel(PreTrainedModel):
    config_class = SecurityQwenConfig
    supports_gradient_checkpointing = True
    
    def __init__(self, config: SecurityQwenConfig):
        super().__init__(config)
        self.config = config
        
        logging.info(f"ğŸ§  Loading base model from: {config.base_model_name_or_path}")
        torch_dtype = torch.float32

        full_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, torch_dtype=torch_dtype, trust_remote_code=True)
        self.qwen_model = full_model.model
        
        self.hidden_size = self.qwen_model.config.hidden_size
        logging.info(f"Base model hidden size detected: {self.hidden_size}")
        
        self.security_head = nn.Sequential(
            nn.Linear(self.hidden_size, config.security_hidden_size), nn.GELU(),
            nn.Dropout(config.dropout_rate), nn.Linear(config.security_hidden_size, 1)
        )
        self.backdoor_head = nn.Sequential(
            nn.Linear(self.hidden_size, config.backdoor_hidden_size), nn.GELU(),
            nn.Dropout(config.dropout_rate), nn.Linear(config.backdoor_hidden_size, 2)
        )
        
        model_dtype = self.qwen_model.dtype
        logging.info(f"Base model dtype is {model_dtype}. Casting custom heads to the same dtype.")
        self.security_head.to(model_dtype)
        self.backdoor_head.to(model_dtype)

        self.post_init()
        logging.info("âœ… SecurityQwenModel initialized successfully with consistent dtypes.")

    def get_input_embeddings(self): return self.qwen_model.get_input_embeddings()
    def set_input_embeddings(self, value): self.qwen_model.set_input_embeddings(value)
    def gradient_checkpointing_enable(self, gradient_checkpointing_kwargs=None): self.qwen_model.gradient_checkpointing_enable(gradient_checkpointing_kwargs=gradient_checkpointing_kwargs)
    def gradient_checkpointing_disable(self): self.qwen_model.gradient_checkpointing_disable()

    def forward(self, input_ids: Optional[torch.Tensor] = None, attention_mask: Optional[torch.Tensor] = None, **kwargs) -> SecurityModelOutput:
        # â€¼ï¸â€¼ï¸â€¼ï¸ æœ€ç»ˆæ ¸å¿ƒä¿®å¤ï¼šç§»é™¤ç¡¬ç¼–ç çš„å‚æ•°ï¼Œå®Œå…¨ä¾èµ–ä¸Šå±‚è°ƒç”¨è€…ä¼ å…¥çš„ kwargs â€¼ï¸â€¼ï¸â€¼ï¸
        base_outputs = self.qwen_model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            **kwargs
        )
        
        hidden_states = base_outputs.last_hidden_state
        if attention_mask is not None:
            sequence_lengths = (torch.sum(attention_mask, dim=1) - 1).long()
            batch_size = input_ids.shape[0]
            pooled_output = hidden_states[torch.arange(batch_size, device=hidden_states.device), sequence_lengths]
        else:
            pooled_output = hidden_states[:, -1]
            
        security_scores = self.security_head(pooled_output).squeeze(-1)
        backdoor_logits = self.backdoor_head(pooled_output)
        
        # `Trainer` æœŸæœ› `forward` è¿”å›ä¸€ä¸ªåŒ…å« lossï¼ˆå¦‚æœæä¾›äº†labelsï¼‰ã€logits ç­‰ä¿¡æ¯çš„å¯¹è±¡
        # åœ¨è¿™é‡Œæˆ‘ä»¬åªè¿”å›æˆ‘ä»¬è‡ªå®šä¹‰å¤´è®¡ç®—çš„ç»“æœã€‚`Trainer` ä¼šåœ¨ `compute_loss` ä¸­å¤„ç†å®ƒä»¬
        return SecurityModelOutput(
            security_scores=security_scores,
            backdoor_logits=backdoor_logits,
            hidden_states=getattr(base_outputs, 'hidden_states', None),
            attentions=getattr(base_outputs, 'attentions', None),
        )

# åœ¨ security_model.py ä¸­æ›¿æ¢

def create_security_model(model_name_or_path: str, load_in_fp16: bool = False, **kwargs):
    logging.info(f"ğŸ­ Creating SecurityQwenModel with base: {model_name_or_path}")
    
    config = SecurityQwenConfig(base_model_name_or_path=model_name_or_path, **kwargs)
    config._load_in_fp16 = load_in_fp16
    
    # 1. å…ˆåˆ›å»ºæˆ‘ä»¬çš„åŸå§‹æ¨¡å‹
    model = SecurityQwenModel(config)
    
    # 2. å®šä¹‰ LoRA é…ç½®
    lora_config = LoraConfig(
        task_type=TaskType.SEQ_CLS,
        inference_mode=False,
        r=8, # LoRAçš„ç§©ï¼Œé€šå¸¸è®¾ä¸º8æˆ–16
        lora_alpha=16, # LoRAçš„alphaå‚æ•°
        lora_dropout=0.1,
        target_modules=["q_proj", "v_proj"], # æŒ‡å®šè¦åº”ç”¨LoRAçš„å±‚
        # â€¼ï¸â€¼ï¸â€¼ï¸ æœ€ç»ˆã€æœ€å…³é”®çš„ä¿®å¤ï¼šå‘Šè¯‰PEFTä¸è¦å†»ç»“æˆ‘ä»¬çš„è‡ªå®šä¹‰å¤´ â€¼ï¸â€¼ï¸â€¼ï¸
        modules_to_save=["security_head", "backdoor_head"]
    )

    # 3. ä½¿ç”¨ get_peft_model åŒ…è£…åŸå§‹æ¨¡å‹
    model = get_peft_model(model, lora_config)
    
    # æ‰“å°å¯è®­ç»ƒå‚æ•°çš„æ•°é‡
    # è¿™æ¬¡ä½ ä¼šçœ‹åˆ° trainable params ä¸å†æ˜¯0ï¼Œè€Œæ˜¯æˆ‘ä»¬è‡ªå®šä¹‰å¤´å’ŒLoRAå±‚çš„å‚æ•°é‡ä¹‹å’Œ
    model.print_trainable_parameters()

    # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    if getattr(model, "supports_gradient_checkpointing", False):
        # ä¿®å¤ PEFT æ¨¡å‹å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹çš„æ–¹å¼
        model.enable_input_require_grads()
        model.gradient_checkpointing_enable()
        logging.info("âœ… Gradient checkpointing enabled for PEFT model.")
    
    return model